{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf9b832-48c7-476a-ac69-4d819228a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples # = 77865\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "class Key:\n",
    "    def __init__(self):\n",
    "        numbers = np.random.permutation(range(1, 100))\n",
    "        alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "        alphabet = ''.join(random.sample(alphabet, len(alphabet)))\n",
    "        self.k = defaultdict(list)\n",
    "        for i, n in enumerate(numbers):\n",
    "            letter = alphabet[i % len(alphabet)]\n",
    "            self.k[letter].append(n)\n",
    "\n",
    "    def cipher(self, text):\n",
    "        return [random.choice(self.k[c]) for c in text]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        output = json.dumps(dict(self.k), cls=NpEncoder, sort_keys=True, indent=4)\n",
    "        output2 = re.sub(r'\": \\[\\s+', '\": [', output)\n",
    "        output3 = re.sub(r',\\s+ (\\d)', r', \\1', output2)\n",
    "        output4 = re.sub(r'\\s+\\]', ']', output3)\n",
    "        return output4\n",
    "\n",
    "def encode(text):\n",
    "    clean_text = re.sub(r'[^A-Z]', '', text.upper())\n",
    "    k = Key()\n",
    "    return k.cipher(clean_text)\n",
    "\n",
    "\n",
    "# Get sequences of text in capital letters which represent\n",
    "# telegrams and contain single whitespaces.\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Cleans a text by keeping only capital letters and single spaces.\n",
    "    \"\"\"\n",
    "    no_eol_text = re.sub(r'\\r', ' ', text)\n",
    "    no_eol_text = re.sub(r'\\n', ' ', text)\n",
    "    \n",
    "    no_tabs_text = re.sub(r'\\t', ' ', no_eol_text)\n",
    "    # print(f\"no tabs = '{no_tabs_text}'\")\n",
    "    \n",
    "    capital_text = re.sub(r'[^A-Za-z\\s]', '', no_tabs_text).strip().upper()\n",
    "    # print(f\"capital = '{capital_text}'\")\n",
    "    \n",
    "    single_space_text = re.sub(r'\\s\\s+', ' ', capital_text)\n",
    "    # print(f\"single space = '{single_space_text}'\")\n",
    "    return single_space_text\n",
    "\n",
    "def get_start(lines):\n",
    "    idx = 0\n",
    "    while idx < len(lines):\n",
    "        if lines[idx].startswith(\"*** START OF THE PROJECT GUTENBERG EBOOK\"):\n",
    "            return idx\n",
    "        idx += 1\n",
    "    return idx\n",
    "\n",
    "def get_end(lines):\n",
    "    idx = len(lines) - 1\n",
    "    while idx > -1:\n",
    "        if lines[idx].startswith(\"*** END OF THE PROJECT GUTENBERG EBOOK\"):\n",
    "            return idx\n",
    "        idx -= 1\n",
    "    return idx\n",
    "\n",
    "max_length = 340\n",
    "def build_texts_from_book(book_name: str):\n",
    "    with open(f\"books/{book_name}\") as f:\n",
    "        lines = [line for line in f]\n",
    "    \n",
    "    start_idx = get_start(lines)\n",
    "    end_idx = get_end(lines)\n",
    "    selected_lines = [line for i, line in enumerate(lines) if start_idx < i < end_idx-2]\n",
    "    \n",
    "    clean_text = clean(\"\".join(selected_lines))\n",
    "    \n",
    "    words = clean_text.split()\n",
    "    i = 0\n",
    "    \n",
    "    the_texts = []\n",
    "    \n",
    "    while i < len(words):\n",
    "        next_text = \"\"\n",
    "        while i < len(words) and len(next_text+words[i])+ 1 < max_length:\n",
    "            next_text += \" \" + words[i]\n",
    "            i+=1\n",
    "        the_texts.append(next_text)\n",
    "    return the_texts\n",
    "\n",
    "def build_texts_from_books(book_names: List[str]):\n",
    "    result = []\n",
    "    for bn in book_names:\n",
    "        result.extend(build_texts_from_book(bn))\n",
    "    return result\n",
    "\n",
    "import os\n",
    "the_books = [x for x in os.listdir(\"books\") if x[-4:] == \".txt\"]\n",
    "the_texts = build_texts_from_books(the_books)\n",
    "\n",
    "total_samples = len(the_texts)\n",
    "nb_train_samples = int(total_samples * 0.8)\n",
    "\n",
    "print(f\"Total samples # = {total_samples}\")\n",
    "\n",
    "with open(\"train/train.en\", \"w\") as f:\n",
    "    for x in the_texts[0:nb_train_samples]:\n",
    "        f.write(x)\n",
    "        f.write(\"\\n\")\n",
    "with open(\"train/train.nb\", \"w\") as g:\n",
    "    for x in the_texts[0:nb_train_samples]:\n",
    "        g.write(\"\".join([f\"{t:02}\" for t in encode(x)]))\n",
    "        g.write(\"\\n\")\n",
    "\n",
    "with open(\"valid/val.en\", \"w\") as f:\n",
    "    for x in the_texts[nb_train_samples:]:\n",
    "        f.write(x)\n",
    "        f.write(\"\\n\")\n",
    "with open(\"valid/val.nb\", \"w\") as g:\n",
    "    for x in the_texts[nb_train_samples:total_samples]:\n",
    "        g.write(\"\".join([f\"{t:02}\" for t in encode(x)]))\n",
    "        g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19810ace-c40e-4b69-a34e-1c465c5a8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'nb' # numbers\n",
    "TGT_LANGUAGE = 'en' # english\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e325dbd-7d74-42c7-9a2d-2c2a00d8a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def token_transform_nb(s) -> List[str]: # s even length, only numbers, \n",
    "    return [s[i:i+2] for i in range(0, len(s), 2)] # should never yield \"00\"\n",
    "\n",
    "def token_transform_en(s) -> List[str]: # s must start with a space and end with letter\n",
    "    i = 0\n",
    "    tokens = []\n",
    "    while i < len(s):\n",
    "        if s[i] == \" \":\n",
    "            tokens.append(s[i:i+2])\n",
    "            i += 2\n",
    "        else:\n",
    "            tokens.append(s[i])\n",
    "            i += 1\n",
    "    return tokens\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = token_transform_nb\n",
    "token_transform[TGT_LANGUAGE] = token_transform_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e558109-184b-4869-ad7d-ee110bef1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "def display_vocab(v):\n",
    "    print(\", \".join(v.lookup_tokens([i for i in range(len(v))])))\n",
    "\n",
    "def vocab_from(arr):\n",
    "    d = OrderedDict()\n",
    "    for x, y in list(zip(arr, range(len(arr)))):\n",
    "        d[x] = y\n",
    "        \n",
    "    voc = vocab(d, min_freq=0, specials=special_symbols, special_first=True)\n",
    "    voc.set_default_index(UNK_IDX)\n",
    "    \n",
    "    return voc\n",
    "\n",
    "def build_numbers_vocab():\n",
    "    numbers = [f\"{i:02}\" for i in range(1, 100)]\n",
    "    return vocab_from(numbers)\n",
    "\n",
    "def build_english_vocab():\n",
    "    letters = [chr(i) for i in range(65, 65+26)]\n",
    "    letters.extend([\" \"+chr(i) for i in range(65, 65+26)])\n",
    "    return vocab_from(letters)\n",
    "    \n",
    "vocab_transform[SRC_LANGUAGE] = build_numbers_vocab()\n",
    "vocab_transform[TGT_LANGUAGE] = build_english_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a5d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.iter import FileOpener\n",
    "\n",
    "def get_data_iter(split: str):\n",
    "    src_dp = dp.iter.FileLister([split]).filter(filter_fn=lambda filename: filename.endswith('.nb'))\n",
    "    src_data_dp = FileOpener(src_dp, encoding=\"utf-8\").readlines(\n",
    "        return_path=False, strip_newline=True\n",
    "    )\n",
    "    \n",
    "    tgt_dp = dp.iter.FileLister([split]).filter(filter_fn=lambda filename: filename.endswith('.en'))\n",
    "    tgt_data_dp = FileOpener(tgt_dp, encoding=\"utf-8\").readlines(\n",
    "        return_path=False, strip_newline=True\n",
    "    )\n",
    "    \n",
    "    return src_data_dp.zip(tgt_data_dp).shuffle().set_shuffle(False).sharding_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa941f4-ac3c-44fc-9703-58229c5a8716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8588c6c-0044-4421-a5fd-5d934b3d6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aa0494-6d10-44fa-92ca-947721ed2a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1450d98a-6d83-4fd6-b814-917204b3af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419ed649-e786-4d01-9597-783c8306f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, epoch_nb):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # train_iter = Cifra(root=\"./\", split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_iter = get_data_iter(\"train\")\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        \n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        \n",
    "        writer.add_scalar(f\"Loss/train epoch #{epoch_nb}\", loss, cnt)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        cnt += 1\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    # val_iter = Cifra(root=\"./\", split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_iter = get_data_iter(\"valid\")\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93c006b-a5e4-4423-baf5-dc78888f0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:144: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 3.207, Val loss: 2.786, Epoch time = 1076.006s\n",
      "Epoch: 2, Train loss: 2.792, Val loss: 2.721, Epoch time = 1145.103s\n",
      "Epoch: 3, Train loss: 2.740, Val loss: 2.699, Epoch time = 1126.058s\n",
      "Epoch: 4, Train loss: 2.712, Val loss: 2.683, Epoch time = 1193.360s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m      8\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(transformer)\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, epoch_nb)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), tgt_out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     27\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train epoch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_nb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, loss, cnt)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/translation/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/translation/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/translation/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, epoch)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f0ef0-9e7f-4764-9391-2a3934942209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate(transformer, \"422213246754308062694958558135649599833490518985738370693929612690755512535741419051487090515799865122852458421691796001346118397857912334993025919397152649255512789594307078759295419536994381625703039590701695023926943008061647127826122264797834485905414828978375584893457083483953951244284305343079066197830889157826925157839545792276285970837559699390571552098559035764260578121991236990128061700191275745131889799096349006394841956603909193577920347223698152261941303077342348387030236448595812488167697064951255245348991286956936093878699290789539\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118a055-0a73-4886-adf0-0557bcd3ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"OF US AND ALL OF US AND SO AS TINY TIM OBSERVED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1195138c-bb42-4b22-ab25-1717dfc7d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"422213246754308062694958558135649599833490518985738370693929612690755512535741419051487090515799865122852458421691796001346118397857912334993025919397152649255512789594307078759295419536994381625703039590701695023926943008061647127826122264797834485905414828978375584893457083483953951244284305343079066197830889157826925157839545792276285970837559699390571552098559035764260578121991236990128061700191275745131889799096349006394841956603909193577920347223698152261941303077342348387030236448595812488167697064951255245348991286956936093878699290789539\")/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa6dde17-3ace-4b99-adf4-40a38a50e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"WOULD BE BLIND ANYWAY HE THOUGHT IT QUITE AS WELL THAT THEY SHOULD WRINKLE UP THEIR EYES IN GRINS AS HAVE THE MALADY IN LESS ATTRACTIVE FORMS HIS OWN HEART LAUGHED AND THAT WAS QUITE ENOUGH FOR HIM HE HAD NO FURTHER INTERCOURSE WITH SPIRITS BUT LIVED UPON THE TOTAL ABSTINENCE PRINCIPLE EVER AFTERWARDS AND IT WAS ALWAYS SAID OF HIM THAT\")-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945d482-2c77-4af4-a1f2-246e553fd6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ca906b-7fb1-4bb8-8d8f-aa4e99cff47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/desaxce/miniconda3/envs/translation/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchvision-0.18.1-cp310-cp310-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.17.0 requires torch==2.2.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.3.1 torchvision-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
